<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.96.0"><meta name=date content="2022-03-26T09:15:58Z"><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><meta name=author content="Luigi Gresele"><meta name=description content><meta name=keywords content="workshop,causal representation"><title>Call for Papers</title><meta property="og:title" content="Call for Papers"><meta property="og:type" content="website"><meta property="og:description" content><meta name=twitter:title content><link rel=canonical href=/call-for-papers/><link rel=stylesheet href=/styles.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><section id=header><h1><a href=/>Workshop on Causal Representation Learning at UAI 2022</a></h1><div id=navigation><ul><li><strong><a href=/about>About</a></strong></li><li><strong><a href=/call-for-papers>Call for Papers</a></strong></li><li><strong><a href=/selected-references>Selected References</a></strong></li><li><strong><a href=/accepted-papers>Accepted Papers</a></strong></li><li><strong><a href=/organizers>Schedule</a></strong></li><li><strong><a href=/organizers>Organizers</a></strong></li></ul></div></section><section id=content><h1 id=call-for-papers>Call for Papers</h1><p>Machine learning (ML) has established itself as the dominant and most successful paradigm for artificial intelligence (AI). A key strength of ML over earlier (symbolic, logic and rule-based) approaches to AI, is its ability to infer useful features or <em>representations</em> of often very high-dimensional observations in an automated, data-driven way. However, in doing so, it generally only leverages <em>statistical</em> information (e.g., correlations present in a training set) and consequently struggles at tasks such as knowledge transfer, systematic generalization, or planning, which are thought to require higher-order cognition.</p><p>Causal inference (CI), on the other hand, is concerned with going beyond the statistical level of description (“seeing”) and instead aims to reason about the effect of interventions or external manipulations to a system (“doing”) as well as about hypothetical counterfactual scenarios (“imagining”). Similar to classic approaches to AI, CI typically assumes that the causal variables of interest (i.e., an appropriate level of description of a given system) are given from the outset. However, real-world data often comprises high-dimensional, low-level observations and is thus usually not structured into such meaningful causal units.</p><p>The emerging field of causal representation learning (CRL) aims to combine the strengths of ML and CI. Much like ML went beyond symbolic AI in not requiring that the symbols that algorithms manipulate be given a priori, in CRL low-dimensional, high-level variables <em>along with their causal relations</em> should be learned from raw, unstructured data, leading to representations that support notions such as intervention, reasoning, and planning. In this sense, CRL aligns with the general goal of modern ML to learn <em>meaningful</em> representations of data, where meaningful can also include <em>robust, explainable,</em> or <em>fair</em>.</p><p>One aim of this first workshop on CRL is to bring together researchers focusing mainly on either CI or representation learning, from both theoretical and applied perspectives. Moreover, the workshop aims at engaging the various communities interested in learning robust and transferable representations from different perspectives, in order to foster an exchange of ideas. Given that this is still a young, emerging line of research, another goal is to establish a common vocabulary and to identify useful frameworks for addressing CRL.</p><p>We welcome submissions related to any aspects of CRL, including but not limited to:</p><ul><li>Learning latent (structural) causal models & structured (deep) generative models</li><li>Interventional representations, causal digital twins & structured (causal) world models</li><li>Post-hoc extraction of causal relations from (deep) generative models</li><li>Self-supervised causal representation learningMulti-environment & multi-view causal representation learning</li><li>Micro vs. macro/coarse-grained/multi-level causal systems</li><li>Identifiable representation learning & nonlinear ICA</li><li>Uncertainty quantification in (causal) representation learning</li><li>Group-theoretic & symmetry-based views on disentanglement</li><li>Invariance & equivariance in representation learning</li><li>Interdisciplinary perspectives on causal representation learning, including from cognitive science, psychology, (computational) neuroscience or philosophy</li><li>Real-world applications of causal representation learning, including in biology, medical sciences, or robotics</li></ul></section><div id=footer>Made with <a href=https://gohugo.io/>Hugo</a> and hosted on <a href=https://github.com/crl-uai-2022/crl-uai-2022.github.io>GitHub</a>.</div></body></html>